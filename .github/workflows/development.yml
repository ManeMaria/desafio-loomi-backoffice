name: CI/CD - Staging - Pipeline
on:
  push:
    branches: [develop]

jobs:
  continuous-deployment:
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/develop'
    steps:
      - name: Checkout the files
        uses: actions/checkout@v3

      - name: Checkout repository
        uses: actions/checkout@v2
        with:
          fetch-depth: 0

      - uses: actions/checkout@v2
        env:
          ARGS: '-rltgoDzvO --delete'
          SOURCE: './'
          TARGET: '/home/ubuntu'
          EXCLUDE: '/dist/, /node_modules/'
          SSH_PRIVATE_KEY: ${{ secrets.SSH_PRIVATE_KEY}}
          REMOTE_HOST: ${{ secrets.REMOTE_HOST }}
          REMOTE_USER: ${{ secrets.REMOTE_USER }}

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Configurar ambiente
        run: |
          echo "O repositório foi clonado em: $GITHUB_WORKSPACE"
          cd $GITHUB_WORKSPACE

      - name: Remove Unused Docker Volumes
        run: docker volume prune --force

      - name: SSH into EC2 instance and run Docker Compose
        uses: appleboy/ssh-action@master

        with:
          host: ${{ secrets.EC2_HOST }}
          username: ${{ secrets.EC2_USERNAME }}
          key: ${{ secrets.EC2_SSH_KEY }}
          port: 22

      - uses: actions/checkout@v2
      - name: Create .env file
        working-directory: ${{ github.workspace }}
        run: |
          sudo echo "API_PORT=${{ secrets.API_PORT }}" >> .env
          sudo echo "API_PORT=${{ secrets.API_PORT }}" >> .env
          sudo echo "DATABASE_HOST=${{ secrets.DATABASE_HOST }}" >> .env
          sudo echo "DATABASE_PORT=${{ secrets.DATABASE_PORT }}" >> .env
          sudo echo "DATABASE_NAME=${{ secrets.DATABASE_NAME }}" >> .env
          sudo echo "DATABASE_USERNAME=${{ secrets.DATABASE_USERNAME }}" >> .env
          sudo echo "DATABASE_PASSWORD=${{ secrets.DATABASE_PASSWORD }}" >> .env
          sudo echo "DATABASE_URL=${{ secrets.DATABASE_URL }}" >> .env
          sudo echo "COGNITO_API_VERSION=${{ secrets.COGNITO_API_VERSION }}" >> .env
          sudo echo "COGNITO_USER_POOL_ID=${{ secrets.COGNITO_USER_POOL_ID }}" >> .env
          sudo echo "COGNITO_CLIENT_ID=${{ secrets.COGNITO_CLIENT_ID }}" >> .env
          sudo echo "COGNITO_REGION=${{ secrets.COGNITO_REGION }}" >> .env
          sudo echo "PRODUCTION_DEPLOY_URL=${{ secrets.PRODUCTION_DEPLOY_URL }}" >> .env
          sudo echo "PRODUCTION_FRONT_DEPLOY_URL=${{ secrets.PRODUCTION_FRONT_DEPLOY_URL }}" >> .env
          sudo echo "STAGE_DEPLOY_URL=${{ secrets.STAGE_DEPLOY_URL }}" >> .env
          sudo echo "STAGE_FRONT_DEPLOY_URL=${{ secrets.STAGE_FRONT_DEPLOY_URL }}" >> .env
          sudo echo "AWS_BUCKET_NAME=${{ secrets.AWS_BUCKET_NAME }}" >> .env
          sudo echo "AWS_BUCKET_REGION=${{ secrets.AWS_REGION }}" >> .env
          sudo echo "AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}" >> .env
          sudo echo "AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}" >> .env

      # - name: Execute docker-compose
      #   working-directory: ${{ github.workspace }}
      #   run: |
      #     CONTAINERS=$(docker ps -q -f status=exited)
      #     if [ -n "$CONTAINERS" ]; then
      #       docker rm -f $CONTAINERS
      #     else
      #       echo "No exited containers to remove."
      #     fi
      #     pwd ${{ github.workspace }}
      #     ls -la  # Exibir novamente o conteúdo do diretório para fins de depuração
      #     docker-compose down
      #     docker-compose up -d api
